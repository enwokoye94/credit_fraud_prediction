{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning (Prediction of transaction type)\n",
    "\n",
    "We will train 4 Classification models to try to predict if a certain transation is fradulant or not.\n",
    "\n",
    "* Logistic Regression\n",
    "* Decision Trees\n",
    "* K-Nearest Neighbor\n",
    "* SVC \n",
    "\n",
    "We will evaluate the models using:\n",
    "* recall score\n",
    "* accuracy score\n",
    "* precision score \n",
    "* f1 score \n",
    "* roc AUC score \n",
    "\n",
    "Due to to the imblance of classes saw in our EDA notebook we will use the estimator with the highest AUC Score, as the best estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initilizing classifiers\n",
    "\n",
    "Log_clf = LogisticRegressionCV()\n",
    "DT_clf = DecisionTreeClassifier()\n",
    "KNC_clf = KNeighborsClassifier()\n",
    "SVC_clf = SVC()\n",
    "\n",
    "\n",
    "classifiers = [Log_clf, DT_clf, KNC_clf, SVC_clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will write a function to predict fraud, and score our results\n",
    "# given the model, the data given, target label, and test size\n",
    "def predict_fraud(model, data, labels, test_size ):\n",
    "    # splitting the training and testing data \n",
    "    X = data.drop(labels, axis=1)\n",
    "    y = data[labels]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=test_size, random_state=42)\n",
    "   \n",
    "    X_train = X_train.values\n",
    "    X_test = X_test.values\n",
    "    y_train = y_train.values\n",
    "    y_test = y_test.values\n",
    "\n",
    "    # fitting the model to the training data\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "\n",
    "    # predicting and returning various metrics\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc_score = accuracy_score(y_test, y_pred) \n",
    "    prec_score = precision_score(y_test, y_pred)\n",
    "    rec_score = recall_score(y_test, y_pred)\n",
    "    auc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    scores = [acc_score, prec_score, rec_score, auc_score ]\n",
    "    return {clf.__class__.__name__: scores}, y_pred, scores  # using dunder methods to return dict with model name, scores for model, and prediction\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ekene\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ekene\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ekene\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ekene\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ekene\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ekene\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ekene\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ekene\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Ekene\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    index  acc_score  prec_score  rec_score  auc_score\n",
      "0    LogisticRegressionCV   0.999223    0.851852   0.617450   0.808640\n",
      "1  DecisionTreeClassifier   0.999085    0.680000   0.798658   0.899030\n",
      "2    KNeighborsClassifier   0.998468    1.000000   0.033557   0.516779\n",
      "3                     SVC   0.998415    0.000000   0.000000   0.500000\n"
     ]
    }
   ],
   "source": [
    "score_results = {}\n",
    "predictions = {}\n",
    "\n",
    "data = pd.read_csv('creditcard.csv')\n",
    "# looping through each of the classifiers we want to evaluate \n",
    "# updating each respective dictonary for scores and actual prediction values\n",
    "for classifier in classifiers:\n",
    "    score_result, prediction, scores = predict_fraud(classifier, data, 'Class', .33)\n",
    "    # print(scores)\n",
    "    score_results.update(score_result)\n",
    "    predictions.update({classifier.__class__.__name__: prediction})\n",
    "\n",
    "# creating dataframes out of dictionaries (easier to view)\n",
    "score_df = pd.DataFrame.from_dict(score_results, orient='index', columns= ['acc_score', 'prec_score', 'rec_score', 'auc_score' ]).reset_index() \n",
    "pred_df = pd.DataFrame.from_dict(predictions)\n",
    "\n",
    "print(score_df.head(len(scores)))\n",
    "# print(pred_df.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally here we can see that though most of the models have a realatively high accuarcy score only DecisionTreeClassifier has an AUC score of .91 which is significantly larger than all the other scores. Though our precision score is lower compareably to tother except for SVC, due to the high imblance in our data AUC score is more importate for correct analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
